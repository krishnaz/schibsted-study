{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "! unzip ml-1m.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = (pd.read_csv('./ml-1m/ratings.dat', engine='python', sep='::', names=['user', 'item', 'rating', 'timestamp'])\n",
    "    .assign(timestamp=lambda df:pd.to_datetime(df.timestamp * 1000000000))\n",
    "          )\n",
    "\n",
    "movies = (pd.read_csv('./ml-1m/movies.dat', engine='python', sep='::', names=['item', 'title', 'genres'])\n",
    "          .assign(genres=lambda df:df.genres.str.split('|').values)\n",
    "          .set_index('item', drop=False))\n",
    "\n",
    "# See http://files.grouplens.org/datasets/movielens/ml-1m-README.txt for more details\n",
    "users = pd.read_csv('./ml-1m/users.dat', engine='python', sep='::', \n",
    "                    names=['user', 'gender', 'age', 'occupation', 'zipcode'])\\\n",
    "    .set_index('user', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:35:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:32:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating           timestamp\n",
       "0     1  1193       5 2000-12-31 22:12:40\n",
       "1     1   661       3 2000-12-31 22:35:09\n",
       "2     1   914       3 2000-12-31 22:32:48\n",
       "3     1  3408       4 2000-12-31 22:04:35\n",
       "4     1  2355       5 2001-01-06 23:38:11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    " * Ideally time based split\n",
    " * For the sake of simplicity, let's just sample ratings uniformly (breaking the time machine rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900209, 4)\n",
      "(100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324271</th>\n",
       "      <td>1922</td>\n",
       "      <td>2094</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-11-20 04:34:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818637</th>\n",
       "      <td>4918</td>\n",
       "      <td>2808</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-07-08 19:29:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148677</th>\n",
       "      <td>957</td>\n",
       "      <td>1660</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-11-25 05:28:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778790</th>\n",
       "      <td>4653</td>\n",
       "      <td>914</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-11-29 21:22:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525489</th>\n",
       "      <td>3245</td>\n",
       "      <td>3324</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-09-07 06:33:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating           timestamp\n",
       "324271  1922  2094       4 2000-11-20 04:34:27\n",
       "818637  4918  2808       1 2000-07-08 19:29:05\n",
       "148677   957  1660       4 2000-11-25 05:28:13\n",
       "778790  4653   914       5 2000-11-29 21:22:43\n",
       "525489  3245  3324       1 2000-09-07 06:33:31"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ratings.sample(n=100000, random_state=0)\n",
    "train_ratings_mask = ~ratings.index.isin(test.index)\n",
    "train = ratings.loc[train_ratings_mask]\n",
    "\n",
    "test_user_items = test[['user', 'item']]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large scale LR model\n",
    "\n",
    "Using TFlearn high-level wrapper\n",
    "https://www.tensorflow.org/versions/r0.9/tutorials/linear/overview.html\n",
    "\n",
    "See also  https://github.com/tflearn/tflearn/blob/master/examples/others/recommender_wide_and_deep.py\n",
    "and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/tutorials/wide_and_deep/index.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900209, 10)\n",
      "(1000209, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>[Animation, Comedy, Thriller]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Antz (1998)</td>\n",
       "      <td>[Animation, Children's]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Girl, Interrupted (1999)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1566</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Hercules (1997)</td>\n",
       "      <td>[Adventure, Animation, Children's, Comedy, Mus...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>[Animation, Children's, Comedy, Musical]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1907</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Mulan (1998)</td>\n",
       "      <td>[Animation, Children's]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>783</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Hunchback of Notre Dame, The (1996)</td>\n",
       "      <td>[Animation, Children's, Musical]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1836</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Last Days of Disco, The (1998)</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Cinderella (1950)</td>\n",
       "      <td>[Animation, Children's, Musical]</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user  item  rating gender  age  occupation zipcode  \\\n",
       "0      1  1193       5      F    1          10   48067   \n",
       "29     1   745       3      F    1          10   48067   \n",
       "30     1  2294       4      F    1          10   48067   \n",
       "31     1  3186       4      F    1          10   48067   \n",
       "32     1  1566       4      F    1          10   48067   \n",
       "33     1   588       4      F    1          10   48067   \n",
       "34     1  1907       4      F    1          10   48067   \n",
       "35     1   783       4      F    1          10   48067   \n",
       "36     1  1836       5      F    1          10   48067   \n",
       "37     1  1022       5      F    1          10   48067   \n",
       "\n",
       "                                     title  \\\n",
       "0   One Flew Over the Cuckoo's Nest (1975)   \n",
       "29                   Close Shave, A (1995)   \n",
       "30                             Antz (1998)   \n",
       "31                Girl, Interrupted (1999)   \n",
       "32                         Hercules (1997)   \n",
       "33                          Aladdin (1992)   \n",
       "34                            Mulan (1998)   \n",
       "35     Hunchback of Notre Dame, The (1996)   \n",
       "36          Last Days of Disco, The (1998)   \n",
       "37                       Cinderella (1950)   \n",
       "\n",
       "                                               genres      genre  \n",
       "0                                             [Drama]      Drama  \n",
       "29                      [Animation, Comedy, Thriller]  Animation  \n",
       "30                            [Animation, Children's]  Animation  \n",
       "31                                            [Drama]      Drama  \n",
       "32  [Adventure, Animation, Children's, Comedy, Mus...  Adventure  \n",
       "33           [Animation, Children's, Comedy, Musical]  Animation  \n",
       "34                            [Animation, Children's]  Animation  \n",
       "35                   [Animation, Children's, Musical]  Animation  \n",
       "36                                            [Drama]      Drama  \n",
       "37                   [Animation, Children's, Musical]  Animation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_and_features = (pd.merge(\n",
    "    left=pd.merge(\n",
    "        left=ratings[['user', 'item', 'rating']],\n",
    "        right=users, on='user', how='left'),\n",
    "    right=movies.assign(genre=lambda df:df.genres.str[0]), on='item', how='left')\n",
    "    .sort_values('user')\n",
    ")\n",
    "\n",
    "train_ratings_and_features = ratings_and_features[ratings_and_features.index.isin(train.index)]\n",
    "test_ratings_and_features = ratings_and_features[ratings_and_features.index.isin(test.index)]\n",
    "print(train_ratings_and_features.shape)\n",
    "print(ratings_and_features.shape)\n",
    "ratings_and_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "gender = tf.contrib.layers.sparse_column_with_hash_bucket(column_name='gender', hash_bucket_size=int(1e4))\n",
    "genre = tf.contrib.layers.sparse_column_with_hash_bucket(column_name='genre', hash_bucket_size=int(1e4))\n",
    "\n",
    "gender_genre = tf.contrib.layers.crossed_column(\n",
    "    [gender, genre], hash_bucket_size=int(1e4))\n",
    "\n",
    "def to_sparse_tensor(ratings_and_features, feature_colum):\n",
    "    n_samples = ratings_and_features.shape[0]\n",
    "    \n",
    "    return tf.SparseTensor(\n",
    "        indices=np.vstack([np.arange(n_samples), np.zeros(n_samples)]).T,\n",
    "        values=ratings_and_features[feature_colum].values,\n",
    "        shape=[n_samples, 1]\n",
    "    )\n",
    "\n",
    "def input_fn(ratings_and_features, categorical_cols):\n",
    "    column_to_tensors = {c: to_sparse_tensor(ratings_and_features, c) for c in categorical_cols}\n",
    "    ratings_as_target = tf.constant(ratings_and_features.rating.values)\n",
    "    return (column_to_tensors, ratings_as_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using high-level TF.Learn\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/tutorials/wide/index.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j5/s4x2vyp17vd_811sn86vgx700000gn/T/tmp6f4kap44\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Setting feature info to {'gender': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'genre': TensorSignature(dtype=tf.string, shape=None, is_sparse=True)}\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(900209)]), is_sparse=False)\n",
      "/Users/gui/miniconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1750: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  result_shape.insert(dim, 1)\n",
      "WARNING:tensorflow:Given features: {'gender': <tensorflow.python.framework.ops.SparseTensor object at 0x11a924da0>, 'genre': <tensorflow.python.framework.ops.SparseTensor object at 0x11a8e7a58>}, required signatures: {'gender': TensorSignature(dtype=tf.string, shape=None, is_sparse=True), 'genre': TensorSignature(dtype=tf.string, shape=None, is_sparse=True)}.\n",
      "WARNING:tensorflow:Given targets: Tensor(\"Const:0\", shape=(100000,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(900209)]), is_sparse=False).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 20\n",
      "loss: 1.2786636352539062\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "train_fn = partial(input_fn, ratings_and_features=train_ratings_and_features, categorical_cols=['gender', 'genre'])\n",
    "test_fn = partial(input_fn, ratings_and_features=test_ratings_and_features, categorical_cols=['gender', 'genre'])\n",
    "\n",
    "lr = learn.LinearRegressor(\n",
    "    feature_columns=[gender, genre, gender_genre])\n",
    "\n",
    "lr.fit(input_fn=train_fn, steps=20)\n",
    "\n",
    "# Evaluate for one step (one pass through the test data).\n",
    "results = lr.evaluate(input_fn=test_fn, steps=1)\n",
    "\n",
    "# Print the stats for the evaluation.\n",
    "for key in sorted(results):\n",
    "    print(\"{}: {}\".format(key, results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using low level helpers with pure TF\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/contrib/layers/python/layers/feature_column_ops.py#L289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'weighted_sum_from_feature_columns/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import feature_column_ops\n",
    "\n",
    "categorical_cols = ['gender', 'genre']\n",
    "\n",
    "weighted_features, _, __ = feature_column_ops.weighted_sum_from_feature_columns(\n",
    "    columns_to_tensors = {c: to_sparse_tensor(ratings_and_features, c) for c in categorical_cols},\n",
    "    feature_columns=[gender, genre],\n",
    "    num_outputs=1)\n",
    "\n",
    "weighted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: batch/test loss = 3.68/3.66\n",
      "Step 10: batch/test loss = 2.96/2.94\n",
      "Step 20: batch/test loss = 2.30/2.21\n",
      "Step 30: batch/test loss = 1.64/1.61\n",
      "Step 40: batch/test loss = 1.22/1.24\n",
      "Step 50: batch/test loss = 1.11/1.11\n",
      "Step 60: batch/test loss = 1.12/1.17\n",
      "Step 70: batch/test loss = 1.10/1.16\n",
      "Step 80: batch/test loss = 1.12/1.11\n",
      "Step 90: batch/test loss = 1.09/1.13\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import feature_column_ops\n",
    "import datetime as dt\n",
    "\n",
    "BATCH_SIZE = 512 * 10\n",
    "N_ITER = 100\n",
    "LOG_DIR = '/tmp/tflearn_logs'\n",
    "\n",
    "def compute_loss(predictions, targets):\n",
    "    with tf.name_scope('loss') as s:\n",
    "        loss = tf.sqrt(tf.reduce_mean(tf.square(tf.sub(predictions, targets))), name='rmse')\n",
    "    return loss\n",
    "\n",
    "def training(loss, learning_rate=0.02):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "import itertools\n",
    "\n",
    "def to_feature_columns(column_names, cross=False):\n",
    "    feature_columns = [\n",
    "        tf.contrib.layers.sparse_column_with_hash_bucket(\n",
    "            column_name, hash_bucket_size=int(1e2))\n",
    "        for column_name in column_names]\n",
    "    crossed_columns = [tf.contrib.layers.crossed_column(columns=[first, second], hash_bucket_size=int(1e3))\n",
    "     for first, second in itertools.combinations(feature_columns, 2)]\n",
    "    return crossed_columns + feature_columns \n",
    "\n",
    "def names_to_values_holders(column_names, batch_size=None):\n",
    "    return {\n",
    "        column_name: tf.placeholder(tf.string, shape=[batch_size], name='sample_' + column_name)\n",
    "        for column_name in column_names}\n",
    "\n",
    "def holders_to_named_tensors(named_values_holders, indices_holder, shape_holder):\n",
    "    return {\n",
    "        column_name: tf.SparseTensor(\n",
    "            indices=indices_holder,\n",
    "            values=values_holder,\n",
    "            shape=shape_holder)\n",
    "        for column_name, values_holder\n",
    "        in named_values_holders.items()}\n",
    "\n",
    "def holders_to_feed_values(ratings_and_features, named_values_holders):\n",
    "    return {\n",
    "        values_holder:ratings_and_features[column_name].values\n",
    "        for column_name, values_holder\n",
    "        in named_values_holders.items()}\n",
    "                             \n",
    "categorical_cols = ['gender', 'genre']\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    ratings_placeholder = ratings_placeholder = tf.placeholder(tf.float32, shape=[None], name='ratings')\n",
    "    indices_holder = tf.placeholder(tf.int64, shape=[None, 2], name='sample_indices')\n",
    "    shape_holder = tf.placeholder(tf.int64, name='samples_shape')\n",
    "    \n",
    "    names_to_values_holders = names_to_values_holders(categorical_cols)\n",
    "    names_to_tensors = holders_to_named_tensors(names_to_values_holders, indices_holder, shape_holder)\n",
    "    \n",
    "    with tf.name_scope('weighted_features') as s:\n",
    "        # see https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/contrib/layers/python/layers/feature_column_ops.py#L289\n",
    "        weighted_sum_features, _, __ = feature_column_ops.weighted_sum_from_feature_columns(\n",
    "            columns_to_tensors=names_to_tensors,\n",
    "            feature_columns=to_feature_columns(categorical_cols),\n",
    "            num_outputs=1, scope=s)\n",
    "\n",
    "    loss = compute_loss(weighted_sum_features, ratings_placeholder)\n",
    "    train_step = training(loss)\n",
    "    \n",
    "    tf.scalar_summary('batch_rmse', loss)\n",
    "    summary = tf.merge_all_summaries()\n",
    "    test_summary = tf.scalar_summary('test_rmse', loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.train.SummaryWriter(LOG_DIR + '/{:%Y%m%d%H%M%S}'.format(dt.datetime.now()), sess.graph)\n",
    "        \n",
    "        holders_to_batch_feed_values = {\n",
    "            indices_holder: np.vstack([np.arange(BATCH_SIZE), np.zeros(BATCH_SIZE)]).T,\n",
    "            shape_holder: [BATCH_SIZE, 1]\n",
    "        }\n",
    "\n",
    "        n_test_samples = 1000\n",
    "        holders_to_test_feed_values = {\n",
    "            indices_holder: np.vstack([np.arange(n_test_samples), np.zeros(n_test_samples)]).T,\n",
    "            shape_holder: [n_test_samples, 1]\n",
    "        }\n",
    "\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for step in range(N_ITER):\n",
    "            rs = train_ratings_and_features.sample(BATCH_SIZE)\n",
    "            holders_to_batch_feed_values.update({ratings_placeholder: rs.rating.values})\n",
    "            holders_to_batch_feed_values.update(holders_to_feed_values(rs, names_to_values_holders))\n",
    "            _, loss_value, summary_value = sess.run(\n",
    "                fetches=[train_step, loss, summary],\n",
    "                feed_dict=holders_to_batch_feed_values)\n",
    "            summary_writer.add_summary(summary_value, global_step=step)\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                test_ratings = test_ratings_and_features.sample(n_test_samples)\n",
    "                holders_to_test_feed_values.update({\n",
    "                        ratings_placeholder: test_ratings.rating.values})\n",
    "                holders_to_test_feed_values.update(holders_to_feed_values(test_ratings, names_to_values_holders))\n",
    "                \n",
    "                test_loss_value, test_summary_value = sess.run(\n",
    "                    fetches=[loss, test_summary],\n",
    "                    feed_dict=holders_to_test_feed_values)\n",
    "                print('Step %d: batch/test loss = %.2f/%.2f' % (step, loss_value, test_loss_value))\n",
    "                summary_writer.add_summary(test_summary_value, global_step=step)\n",
    "\n",
    "        summary_writer.flush()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
